epoch:
- args:
    iter_num: 500
    log_interval: 250
    log_vars: [loss, accuracy_top1]
  flow: train
  policy: iterate
- args:
    iter_num: 30
    log_vars: [loss, accuracy_top1]
  flow: val
  policy: iterate
extra:
  custom_modules: []
  custom_paths: []
flows:
- train:
    batch_size: 128
    devices: gpu(0)
    feeder:
      num_thread: 20
      pipeline:
      - attr: {listfile: /mnt/gv7/16winter/ijcai/imagelist/cifar100/cifar.train.txt,
          prefix: /mnt/gv7/dataset/cifar100/images/train/, shuffle: true}
        expr: data, label = file_list()
      - {expr: data = decode(data)}
      - attr: {pad_size: 2}
        expr: data = pad(data)
      - attr: {crop_size: 32, fix_corner: false, mode: random_crop}
        expr: data = crop(data)
      - {expr: data = flip(data)}
      - attr:
          offset: [114, 123, 125]
        expr: data = scaleOffset(data)
    learn:
      lr: 0.1
      lr_policy: multistep(0.1, 30000, 45000)
      min_lr: 1.0e-05
      updater: {momentum: 0.9, type: sgd}
      weight_decay: 0.0005
    spec:
      inputs: [data, label]
      losses: [loss]
      outputs: [loss, accuracy_top1]
- val:
    batch_size: 100
    devices: gpu(0)
    feeder:
      num_thread: 20
      pipeline:
      - attr: {listfile: /mnt/gv7/16winter/ijcai/imagelist/cifar100/cifar.test.txt,
          prefix: /mnt/gv7/dataset/cifar100/images/test/, shuffle: false}
        expr: data, label = file_list()
      - {expr: data = decode(data)}
      - attr:
          offset: [114, 123, 125]
        expr: data = scaleOffset(data)
    spec:
      inputs: [data, label]
      losses: [loss]
      outputs: [loss, accuracy_top1]
init_missing: true
loggers:
- {type: local}
- args: {password: 123456, url: 'http://pavi.parrotsdnn.org/log', username: demo}
  type: pavi
max_iter: 60000
model: {yaml: resnet.yaml}
record_best: {factor: -1, field: accuracy_top1, val_flow: val}
snapshot_interval: 1000
work_dir: ./
