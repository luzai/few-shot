{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxinglu/anaconda2/lib/python2.7/site-packages/networkx/drawing/nx_pylab.py:126: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  b = plt.ishold()\n",
      "/home/wangxinglu/anaconda2/lib/python2.7/site-packages/networkx/drawing/nx_pylab.py:138: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
      "    Future behavior will be consistent with the long-time default:\n",
      "    plot commands add elements without first clearing the\n",
      "    Axes and/or Figure.\n",
      "  plt.hold(b)\n",
      "/home/wangxinglu/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:917: UserWarning: axes.hold is deprecated. Please remove it from your matplotlibrc and/or style files.\n",
      "  warnings.warn(self.msg_depr_set % key)\n",
      "/home/wangxinglu/anaconda2/lib/python2.7/site-packages/matplotlib/rcsetup.py:152: UserWarning: axes.hold is deprecated, will be removed in 3.0\n",
      "  warnings.warn(\"axes.hold is deprecated, will be removed in 3.0\")\n"
     ]
    }
   ],
   "source": [
    "from metadata import *\n",
    "G=graph\n",
    "# same layout using matplotlib with no labels\n",
    "plt.title('draw_networkx')\n",
    "pos=nx.nx_agraph.graphviz_layout(G)\n",
    "nx.draw(G, pos, with_labels=False, arrows=False)\n",
    "plt.savefig('nx_test2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nimgs={}\n",
    "os.chdir('/mnt/nfs1703/kchen/imagenet-raw/')\n",
    "for d in os.listdir('.'):\n",
    "    nimgs[d]=len(os.listdir(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto select gpu\n",
      " ID  GPU  MEM\n",
      "--------------\n",
      "  0  55%  66%\n",
      "  1  62%  69%\n",
      "  2  68%  69%\n",
      "  3   0%  35%\n",
      "  4   0%   0%\n",
      "  5   0%   0%\n",
      "  6   0%   1%\n",
      "  7   0%   1%\n",
      "available [4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Auto select gpu\n",
      " ID  GPU  MEM\n",
      "--------------\n",
      "  0  41%  66%\n",
      "  1  98%  69%\n",
      "  2  99%  69%\n",
      "  3   0%  35%\n",
      "  4   0%   1%\n",
      "  5   0%   0%\n",
      "  6   0%   1%\n",
      "  7   0%   1%\n",
      "available [5]\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import utils\n",
    "utils.init_dev(utils.get_dev())\n",
    "utils.allow_growth()\n",
    "\n",
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from cifar100_train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets.cifar100 import * \n",
    "import utils \n",
    "from datasets import cifar100\n",
    "from cifar100_train import * \n",
    "\n",
    "batch_size=FLAGS.batch_size\n",
    "\n",
    "# load the dataset\n",
    "dataset = cifar100.get_split('train', FLAGS.data_dir)\n",
    "\n",
    "# load batch of dataset\n",
    "data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "        dataset,\n",
    "        num_readers=8,\n",
    "        common_queue_capacity=40 * batch_size,\n",
    "        common_queue_min=20 * batch_size)\n",
    "\n",
    "images, labels = data_provider.get(['image', 'label'])\n",
    "\n",
    "\n",
    "sess=tf.Session(config= utils.allow_growth_config()) \n",
    "_=tf.train.queue_runner.start_queue_runners(sess)\n",
    "\n",
    "\n",
    "# lb=0\n",
    "# while lb!=52:\n",
    "im,lb=sess.run([images,labels])\n",
    "\n",
    "from datasets.cifar100 import *\n",
    "# a2b_map = {a:b for b,a in b2a_map.items()}\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(im,)\n",
    "plt.grid('off')\n",
    "print lb\n",
    "# blb=a2b_map[lb]\n",
    "# print blb \n",
    "print fine_labels_human[lb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {4, 30, 55, 72, 95},\n",
       " 1: {1, 32, 67, 73, 91},\n",
       " 2: {54, 62, 70, 82, 92},\n",
       " 3: {9, 10, 16, 28, 61},\n",
       " 4: {0, 51, 53, 57, 83},\n",
       " 5: {22, 39, 40, 86, 87},\n",
       " 6: {5, 20, 25, 84, 94},\n",
       " 7: {6, 7, 14, 18, 24},\n",
       " 8: {3, 42, 43, 88, 97},\n",
       " 9: {12, 17, 37, 68, 76},\n",
       " 10: {23, 33, 49, 60, 71},\n",
       " 11: {15, 19, 21, 31, 38},\n",
       " 12: {34, 63, 64, 66, 75},\n",
       " 13: {26, 45, 77, 79, 99},\n",
       " 14: {2, 11, 35, 46, 98},\n",
       " 15: {27, 29, 44, 78, 93},\n",
       " 16: {36, 50, 65, 74, 80},\n",
       " 17: {47, 52, 56, 59, 96},\n",
       " 18: {8, 13, 48, 58, 90},\n",
       " 19: {41, 69, 81, 85, 89}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2f_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapp={}\n",
    "for c,fs in c2f_map.items():\n",
    "    for f in fs:\n",
    "        if coarse_labels_human[c] not in mapp: \n",
    "            mapp[coarse_labels_human[c]]={fine_labels_human[f]}\n",
    "        else:\n",
    "            mapp[coarse_labels_human[c]].add(fine_labels_human[f])\n",
    "mapp            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS.batch_size=batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto select gpu\n",
      " ID  GPU  MEM\n",
      "--------------\n",
      "  0  84%  66%\n",
      "  1  96%  69%\n",
      "  2  98%  69%\n",
      "  3   0%  35%\n",
      "  4   0%  35%\n",
      "  5   0%   0%\n",
      "  6   0%   1%\n",
      "  7   0%   1%\n",
      "available [5]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input/image:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "# load the dataset\n",
    "dataset = cifar100.get_split('train', FLAGS.data_dir)\n",
    "\n",
    "# load batch of dataset\n",
    "batch_queue = load_batch(\n",
    "    dataset,\n",
    "    FLAGS.batch_size,\n",
    "    is_training=True)\n",
    "images, labels = batch_queue.dequeue()\n",
    "slim.summary.image('input/image', images)\n",
    "\n",
    "# tf.get_variable_scope().reuse_variables()\n",
    "# run the image through the model\n",
    "predictions, end_points = resnet50(images, classes=dataset.num_classes)\n",
    "tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    \n",
    "# get the cross-entropy loss\n",
    "one_hot_labels = slim.one_hot_encoding(\n",
    "    labels,\n",
    "    dataset.num_classes)\n",
    "\n",
    "loss_100 = tf.losses.softmax_cross_entropy(\n",
    "    logits=predictions,\n",
    "    onehot_labels=one_hot_labels)\n",
    "\n",
    "labels_coarse = tf.py_func(f2c, [labels], tf.int64)\n",
    "# labels_coarse= tf.reshape(tf.concat(tf.constant(1,tf.int64), labels_coarse), [ 1,2])\n",
    "labels_coarse = tf.reshape(labels_coarse, labels.shape)\n",
    "labels_fine = tf.py_func(c2f, [labels_coarse], tf.int64)\n",
    "labels_fine = tf.reshape(labels_fine, labels.shape.as_list() + [5, ])\n",
    "\n",
    "one_hot_labels_coarse = tf.reduce_sum(\n",
    "        tf.reshape(\n",
    "            tf.to_int64(\n",
    "                slim.one_hot_encoding(\n",
    "                    tf.reshape(labels_fine, (-1,)),\n",
    "                    num_classes=dataset.num_classes\n",
    "                )\n",
    "            ),\n",
    "            labels.shape.as_list() + [5, -1]),\n",
    "        axis=1\n",
    ")\n",
    "loss_20 = tf.losses.log_loss(\n",
    "        predictions=tf.nn.softmax(predictions),\n",
    "        labels=one_hot_labels_coarse,\n",
    "        weights=FLAGS.beta,\n",
    "        loss_collection=None if not FLAGS.multi_loss else tf.GraphKeys.LOSSES\n",
    "    )\n",
    "\n",
    "bs = labels_fine.shape[0]\n",
    "predictions_l = []\n",
    "for ind in range(5):\n",
    "    sel = tf.stack([tf.range(bs, dtype=tf.int64), labels_fine[:, ind]], axis=1)\n",
    "    predictions_l.append(tf.gather_nd(predictions, sel))\n",
    "predictions_group = tf.stack(predictions_l, axis=1)\n",
    "\n",
    "labels_group_one_hot = tf.equal(labels_fine, tf.expand_dims(labels, axis=-1))\n",
    "labels_group_one_hot = tf.to_int64(labels_group_one_hot)\n",
    "\n",
    "loss_group = tf.losses.softmax_cross_entropy(\n",
    "    logits=predictions_group,\n",
    "    onehot_labels=labels_group_one_hot,\n",
    "    weights=FLAGS.gamma,\n",
    "    loss_collection=None if not FLAGS.multi_loss else tf.GraphKeys.LOSSES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.Session(config=utils.allow_growth_config())\n",
    "_=tf.train.queue_runner.start_queue_runners(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init from pretrained model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "variables_to_restore = slim.get_variables_to_restore(\n",
    "        exclude=[\".*logits.*\", \".*Ftrl.*\", '.*Momentum.*', 'global_step'])\n",
    "FLAGS.checkpoint_path='/home/wangxinglu/prj/few-shot/output/multiloss-dbg/model.ckpt-85745'\n",
    "init_assign_op, init_feed_dict = slim.assign_from_checkpoint(\n",
    "        FLAGS.checkpoint_path, variables_to_restore)\n",
    "\n",
    "print 'init from pretrained model'\n",
    "sess.run([init_assign_op, ], init_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=_28[2]\n",
    "ohlc=_28[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 100), (1, 100))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape,ohlc.shape\n",
    "\n",
    "def softmax(x):\n",
    "    # return np.exp(x) / np.sum(np.exp(x), axis=1).reshape(-1, 1)\n",
    "    x = np.array(x)\n",
    "    ex = np.exp(x - x.max(axis=1).reshape(-1, 1))\n",
    "    # print ex.shape\n",
    "    return ex / ex.sum(axis=1).reshape(-1, 1)\n",
    "predt=softmax(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.992187"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt=predt.squeeze()[ohlc.squeeze().astype(bool)]\n",
    "-np.log(tt.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
